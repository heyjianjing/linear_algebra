{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### `Uncertainty` in linear model"
      ],
      "metadata": {
        "id": "CfWMiHIGCqu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume $y=Ax+v$, where $A\\in \\mathbf{R}^{m \\times n}$ and $v$ is measurement noise\n",
        "\n",
        "Assume we have a `norm-bound` noise model $\\|v\\|\\leq \\alpha$\n",
        "\n",
        "If we have an decoder $B$ such that $BA=I$, then\n",
        "\n",
        "* estimator of signal $x$ is $\\bar{x}=By$\n",
        "* noise is also `amplified` by $B$ as $Bv$\n",
        "\n",
        "Therefore, the estimation error\n",
        "\n",
        "$$\\epsilon =\\bar{x} - x=Bv$$\n",
        "\n",
        "which is an `ellipsoid`\n",
        "\n",
        "$$\\epsilon \\in \\{Bv | \\|v\\| \\leq \\alpha\\}$$"
      ],
      "metadata": {
        "id": "J5hMs6qQDB-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For example, if $B$ has `singular values` $5, 0.02, 0.01$, then we can say in one direction the uncertainty is large, and in other two directions, we are confident about the estimation"
      ],
      "metadata": {
        "id": "XYyciQxjEgY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Semiaxes` of the ellipsoid are given by $\\boxed{\\alpha \\sigma_i u_i}$ and `largest norm` of error is simply $\\alpha \\|B\\|=\\alpha \\sigma_1$"
      ],
      "metadata": {
        "id": "8oT8mAuWE7un"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Least squares estimator gives `smallest` uncertainty ellipsoid among all left inverses"
      ],
      "metadata": {
        "id": "yp-SdwaUJ8Iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `Two types` of ellipsoid"
      ],
      "metadata": {
        "id": "pf8cXMSJJ-cI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(1) for $A=A^T>0$ the following set is an ellipsoid\n",
        "\n",
        "$$E=\\{x | x^TAx \\leq 1\\}$$\n",
        "\n",
        "To see why it is an ellipsoid, we can take `eigendecomposition` of $A$\n",
        "\n",
        "$$A=Q\\Lambda Q^T=\\sum_{i=1}^n\\lambda_i q_i q_i^T$$\n",
        "\n",
        "Then, we let $y=Q^Tx$ and we have $x=Qy$ (which follows that $Q$ is orthogonal for symmetric matrix, $Q^{-1}=Q^T$)\n",
        "\n",
        "Now, we can rewrite the expression $x^TAx\\leq 1$ as\n",
        "\n",
        "$$x^TAx=y^TQ^TQ\\Lambda Q^TQy=y^T\\Lambda y=y_1^2\\lambda_1+\\cdots+y_n^2\\lambda_n\\leq 1$$\n",
        "\n",
        "and we get the standard ellipsoid equation\n",
        "\n",
        "$$\\frac{y_1^2}{\\left(\\lambda_1^{-1/2}\\right)^2}+\\cdots+\\frac{y_n^2}{\\left(\\lambda_n^{-1/2}\\right)^2}\\leq 1$$\n",
        "\n",
        "* `semiaxes` are given by $\\boxed{s_i=\\lambda_i^{-1/2}q_i}$, that is, direction of `eigenvectors` of $A$\n",
        "\n",
        "* above can also be verified by plugging $s_i$ into $x^TAx$ and the output is 1\n",
        "\n",
        "* in direction $q_1$ (with $\\lambda_1=\\lambda_{max}$), $x^TAx$ is `large`, hence ellipsoid is `thin` (may be counterintuitive at first. Intuitively, this means in $q_1$ direction, 1 is reached the `fastest`)\n",
        "\n",
        "* in direction $q_n$, $x^TAx$ is `small`, hence ellipsoid is `fat`\n",
        "\n",
        "* $\\sqrt{\\lambda_{max}/\\lambda_{min}}$ gives max eccentricity"
      ],
      "metadata": {
        "id": "Mqq-DJJDKC6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(2) the following set is also an ellipsoid\n",
        "\n",
        "$$E = \\{Ax | \\|x\\| \\leq 1\\}$$\n",
        "\n",
        "* this is achieved by when we `inflate` a `unit ball`, namely $\\|x\\| \\leq 1$, using matrix $A$\n",
        "\n",
        "* `semiaxes` after inflation are given by $\\boxed{\\sigma_i u_i}$, that is, direction of `left singular vectors`\n",
        "\n",
        "* from the following, we know $x$'s in directions of `right singular vectors` $v_i$ in the original unit ball are transformed to semiaxes\n",
        "\n",
        "$$\\boxed{Bv_i=\\sum_{i=1}^r\\sigma_i u_i v_i^Tv_i=\\sigma_iu_i}$$\n",
        "\n",
        "* in direction $u_1$, the inflation is the `largest` $\\sigma_1$, hence ellipsoid is `fat`"
      ],
      "metadata": {
        "id": "u7YesgcLLg2D"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1gbNmoWEFTE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}