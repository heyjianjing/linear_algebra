{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMeJtVyMBJjP92XzrtJgLhF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#### Schur decomposition"],"metadata":{"id":"RzSDlfgPUCzC"}},{"cell_type":"markdown","source":["According to `Schur theorem`, if $A\\in \\mathbf{R}^{n \\times n}$ is a square real matrix, and for simplicity, with `distinct real` eigenvalues, then there exists an orthogonal matrix $Q$ and an upper triangular matrix $T$ such that\n","\n","$$A=QTQ^T$$\n","\n","We can show why this is true"],"metadata":{"id":"Go0h4wvkyC7X"}},{"cell_type":"markdown","source":["##### Setup"],"metadata":{"id":"oivz6pIXGM3X"}},{"cell_type":"markdown","source":["For orthogonal matrix $Q_1^T=Q_1^{-1}$ and $Q_1^TQ_1=I$, by letting $Q_1=\\begin{bmatrix}q_1 & q_2 & \\cdots & q_n\\end{bmatrix}$, and $q_1$ being a normalized `eigenvector` of $A$, we can write\n","\n","$$\\begin{align*}\n","Q_1^TAQ_1&=\\begin{bmatrix}q_1^T \\\\ q_{2:n}^T\\end{bmatrix}A\\begin{bmatrix}q_1 & q_{2:n}\\end{bmatrix} \\\\\n","& =\\begin{bmatrix}q_1^TAq_1 & q_1^TAq_{2:n} \\\\ q_{2:n}^TAq_1 & q_{2:n}^TAq_{2:n}\\end{bmatrix}\n","\\end{align*}$$"],"metadata":{"id":"_lHxQHBczOh6"}},{"cell_type":"markdown","source":["By `construction`, the upper-left block is the corresponding `eigenvalue` $\\lambda_1$, since\n","\n","$$q_1^TAq_1 = q_1^T(\\lambda_1q_1)=\\lambda_1q_1^Tq_1=\\lambda_1$$\n","\n","For the upper-right block, we denote it $B$\n","\n","$$B=q_1^TAq_{2:n}=\\begin{bmatrix}q_1^TAq_2 & q_1^TAq_3 & \\cdots & q_1^TAq_n \\end{bmatrix}$$\n","\n","The lower-left block is zero, since\n","\n","$$q_{2:n}^TAq_1=\\begin{bmatrix}q_2^T \\\\q_3^T \\\\ \\vdots \\\\q_n^T \\end{bmatrix}Aq_1=\\lambda_1\\begin{bmatrix}q_2^T \\\\q_3^T \\\\ \\vdots \\\\q_n^T \\end{bmatrix}q_1=\\begin{bmatrix}0 \\\\0 \\\\ \\vdots \\\\0 \\end{bmatrix}$$\n","\n","We denote the lower-right block $A_2$ and we have\n","\n","$$\\begin{align*}\n","Q_1^TAQ_1&=\\begin{bmatrix}\\lambda_1 & B \\\\ 0 & A_2\\end{bmatrix}\n","\\end{align*}$$\n","\n","or\n","\n","$$\\begin{align*}\n","AQ_1&=Q_1\\begin{bmatrix}\\lambda_1 & B \\\\ 0 & A_2\\end{bmatrix}\n","\\end{align*}$$"],"metadata":{"id":"6UWPzdfPBqPA"}},{"cell_type":"markdown","source":["In addition, $A_2$ contains the `remaining eigenvalues` $\\lambda_2 , \\cdots, \\lambda_n$ of $A$\n","\n","To see this, from the properties of similarity transformation, we know that $A$ and $Q_1^TAQ_1$ have the same eigenvalues\n","\n","Therefore\n","\n","$$\\begin{align*}\n","\\det (A-\\lambda I)&=\\det (Q_1^TAQ_1-\\lambda I) \\\\\n","&=\\det \\begin{bmatrix}\\lambda_1-\\lambda & B \\\\ 0 & A_2-\\lambda I\\end{bmatrix} \\\\\n","& \\text{property of determinant}\\\\\n","&= (\\lambda_1-\\lambda) \\det (A_2-\\lambda I)\n","\\end{align*}$$"],"metadata":{"id":"D96ESkIVGb0b"}},{"cell_type":"markdown","source":["##### Proof by induction"],"metadata":{"id":"MHuuAkPCGUe-"}},{"cell_type":"markdown","source":["For matrix of size one, Schur decomposition obviously exists\n","\n","So starting with matrix of size $n=2$, we know that there exists a Schur decomposition for matrix $A_2$ of size $n-1$:\n","\n","$$Q_2T_2Q_2^T=A_2$$\n","\n","or\n","\n","$$Q_2T_2=A_2Q_2$$\n","\n","We can proceed with `induction`"],"metadata":{"id":"C8AoGPuZFhU1"}},{"cell_type":"markdown","source":["If we write\n","\n","$$Q=Q_1\\begin{bmatrix}1 & 0 \\\\ 0 & Q_2\\end{bmatrix}$$\n","\n","(since both $Q_1$ and $Q_2$ are orthogonal, $Q$ is orthogonal)\n","\n","we have for matrix $A$ of size $n$\n","\n","$$\\begin{align*}AQ &= A Q_1\\begin{bmatrix}1 & 0 \\\\ 0 & Q_2\\end{bmatrix} \\\\\n","& = Q_1\\begin{bmatrix}\\lambda_1 & B \\\\ 0 & A_2\\end{bmatrix}\\begin{bmatrix}1 & 0 \\\\ 0 & Q_2\\end{bmatrix} \\\\\n","&=Q_1 \\begin{bmatrix}\\lambda_1 & BQ_2 \\\\ 0 & A_2Q_2\\end{bmatrix} \\\\\n","&=Q_1 \\begin{bmatrix}\\lambda_1 & BQ_2 \\\\ 0 & Q_2T_2\\end{bmatrix} \\\\\n","&=Q_1 \\begin{bmatrix}1& 0 \\\\ 0 & Q_2\\end{bmatrix}\\begin{bmatrix}\\lambda_1 & BQ_2 \\\\ 0 & T_2\\end{bmatrix} \\\\\n","& = Q\\begin{bmatrix}\\lambda_1 & BQ_2 \\\\ 0 & T_2\\end{bmatrix}\n","\\end{align*}$$\n","\n","Now, we can show that Schur decomposition exists for matrix $A$ of size $n$ by letting\n","\n","$$T=\\begin{bmatrix}\\lambda_1 & BQ_2 \\\\ 0 & T_2\\end{bmatrix}\n","$$"],"metadata":{"id":"0Ch6hX8A_2pa"}},{"cell_type":"markdown","source":["##### Upper triangular matrix has eigenvalues on its diagonal"],"metadata":{"id":"21g-a5fO7NSc"}},{"cell_type":"markdown","source":["With similarity transformation $A=QTQ^T$, we know that $A$ and $T$ have the same eigenvalues\n","\n","Let $t_{ii}, i=1, \\cdots, n$ be diagonal elements of $T$, then by definition of eigenvalues and the fact that determinant of upper triangular matrix is product of its diagonal elements, we have\n","\n","$$\\det(T-\\lambda I)=\\prod_{i=1}^n (t_{ii}-\\lambda)=0$$\n","\n","indicating that eigenvalues of $T$, and thus of $A$ are `diagonal elements` in $T$\n","\n","This is useful as we can obtain eigenvalues of $A$ by transforming $A$ into `Schur form`"],"metadata":{"id":"M5w525J57X0i"}},{"cell_type":"markdown","source":["If $A$ is `symmetric`, then $T$ is upper triangular and symmetric at the same time, therefore, $T$ must be `diagonal`, meaning that symmetric matrices are diagonalizable, as we have known"],"metadata":{"id":"TASdu2t5PHg7"}},{"cell_type":"markdown","source":["#### Orthogonal iterations"],"metadata":{"id":"Q3r1s6EOgAva"}},{"cell_type":"markdown","source":["Recall our power iterations to find the dominant eigenvalue of $A$, by starting from an arbitrary vector $x$ and alternating between computing $y^k=Ax^k$ and normalizing and updating $x^k$ as $x^k=\\frac{y^k}{\\|y^k\\|}$"],"metadata":{"id":"ZLXw7q3vjiz0"}},{"cell_type":"markdown","source":["To get to Schur decomposition, we would like to do the iterations not just on a single vector $x$, but on $n$ orthonormal vectors that form an `orthogonal` matrix $Q_0$\n","\n","After each multiplication of $A$, we do `QR decomposition` such that we still have a set of orthonormal vectors for the next iteration\n","\n","$$AQ_i=Q_{i+1}R_{i+1}$$\n","\n","We can see that, if $Q_i \\rightarrow Q$ as $i\\rightarrow \\infty$, then $R_i$ must also converges to certain upper triangular $R$, and\n","\n","$$AQ=QR \\Rightarrow A=QRQ^T$$\n","\n","which is exactly the Schur decomposition we need where $T=R$"],"metadata":{"id":"g7aCDu29gfgr"}},{"cell_type":"markdown","source":["#### Compute eigenvectors from Schur form"],"metadata":{"id":"LEoOCsa0GbCh"}},{"cell_type":"markdown","source":["Once we have the Schur form $AQ=QT$, if we plug in `eigendecomposition` of the upper triangular $T$, that is $TV=V\\Lambda$ (since $A$ and $T$ are similar, therefore $T$ has distinct real eigenvalues and is diagonalizable), we have\n","\n","$$AQV=QTV=Q(TV)=QV\\Lambda$$\n","\n","We see that, by definition, $QV$ must be the `eigenvectors` of $A$\n","\n","This provides a way to compute eigenvectors of $A$ from orthogonal iterations"],"metadata":{"id":"b3VV6u_VlGMm"}},{"cell_type":"markdown","source":["Assume we want to compute `ith` eigenvector of $T$, then we can let it be of the form\n","\n","$$v_i=\\begin{bmatrix}\\times \\\\ \\times \\\\ \\vdots \\\\ \\times \\\\ 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\\\ 0 \\end{bmatrix}$$\n","\n","That is, the leading $(i-1)$ entries are not necessarily 0, the `ith` entry is 1, and the remaining are all zero\n","\n","Plug in definition of eigenvalue/vector, we have\n","\n","$$Tv_i=t_{ii}v_i \\Longrightarrow (T-t_{ii}I)v_i=0$$\n","\n","This is a system of $(i-1)$ equations that is already in upper triangular form, which can be solved using back substitution"],"metadata":{"id":"GoY-DI7Zh0SU"}},{"cell_type":"markdown","source":["#### Example"],"metadata":{"id":"1XO3qEglReyh"}},{"cell_type":"markdown","source":["We can first evaluate orthogonal iterations on a square real matrix to get some feeling\n","\n","We start with $Q_0=I$\n","\n","We use `Householder` reflector for QR factorization"],"metadata":{"id":"PaQNtZPckP0y"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","np.set_printoptions(formatter={'float': '{: 0.4f}'.format})\n","\n","plt.style.use('dark_background')\n","# color: https://matplotlib.org/stable/gallery/color/named_colors.htm"],"metadata":{"id":"E7IXLxroydqP","executionInfo":{"status":"ok","timestamp":1732898269165,"user_tz":300,"elapsed":105,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def householder(A):\n","    m, n = A.shape\n","    R = A.copy()\n","    Q = np.identity(m)\n","\n","    # For fat matrices, we only process up to the mth column\n","    for i in range(min(m, n)):\n","        x = R[i:, i]\n","        if np.allclose(x, 0):\n","            continue  # Skip if x is a zero vector\n","\n","        v = x.copy()\n","        sng = np.sign(x[0]) if x[0] != 0 else 1.0 # Per convention in NLA\n","        v[0] += sng * np.linalg.norm(x)\n","        v /= np.linalg.norm(v)\n","\n","        # Since all entries in R[i:, :i] are zero from previous iteration\n","        # applying transformation to R[i:, i:] would suffice\n","        R[i:, i:] -= 2 * np.outer(v, v) @ R[i:, i:]\n","\n","        # If Q is needed explicitly\n","        Q[i:, :] -= 2 * np.outer(v, v) @ Q[i:, :]\n","\n","    return Q.T, R\n","\n","def back_substitution(R, b):\n","    m, n = R.shape\n","    x = np.zeros(n)\n","    for i in range(n - 1, -1, -1):\n","        x[i] = (b[i] - np.dot(R[i, i + 1:], x[i + 1:])) / R[i, i]\n","    return x\n","\n","def diagonalizable_mat(n):\n","    # Create diagonal matrix D with eigenvalues\n","    D = np.diag(np.concatenate((200*np.random.rand(n//2)-100, 0.1*np.random.rand(n-n//2))))\n","\n","    # Generate a random invertible matrix\n","    P = np.random.rand(n, n)\n","    while np.linalg.cond(P) > 1e8:  # Check conditioning\n","        P = np.random.rand(n, n)\n","\n","    # Use similarity transformation to create diagonalizable, but nonsymmetric matrix\n","    return P @ D @ np.linalg.inv(P)"],"metadata":{"id":"BF5Ag0ajpknc","executionInfo":{"status":"ok","timestamp":1732898269275,"user_tz":300,"elapsed":2,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["np.random.seed(50)\n","symmetric = False\n","\n","A_size = 8\n","A = diagonalizable_mat(A_size)\n","\n","if symmetric:\n","    A = (A+A.T)/2\n","\n","A_original = A.copy()\n","\n","# Orthogonal iterations\n","Q = np.eye(A.shape[0])\n","Q_0 = Q.copy()\n","\n","num_iter = 201\n","for i in range(num_iter):\n","    Q, R = householder(A @ Q)\n","    # Diagonal elements of R are approximation of eigenvalues\n","    if i % 40 == 0:\n","        print(R.diagonal())\n","\n","v = []\n","n = R.shape[0]\n","for i in range(n):\n","    R_sub = R[:i, :i] - R[i, i] * np.eye(i) # Subportion of R\n","    b = -R[:i, i] # - Truncated ith column of R as b\n","    if i > 0:\n","        v_upper = back_substitution(R_sub, b)\n","    else:\n","        v_upper = np.array([])  # Empty array when i == 0\n","\n","    v_i = np.zeros(n) # Initialize zero vector\n","    v_i[:i] = v_upper # Fill in portion before ith entry\n","    v_i[i] = 1 # ith entry is always one\n","    v_i /= np.linalg.norm(v_i)\n","    v.append(v_i)\n","\n","v = np.column_stack(v)\n","# r, v = np.linalg.eig(R)\n","print(f'\\nEigenvectors from orthogonal iterations: \\n{Q @ v}')\n","\n","# Compare to NumPy\n","eigenvalues, eigenvectors = np.linalg.eig(A_original)\n","print(f'\\nEigenvalues from NumPy: \\n{eigenvalues}')\n","print(f'\\nEigenvectors from NumPy: \\n{eigenvectors}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AWHibPJJkySL","executionInfo":{"status":"ok","timestamp":1732898269895,"user_tz":300,"elapsed":621,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}},"outputId":"96f141e5-9f5b-43bb-ff96-915ea0745311"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 124.4855 -31.3821 -16.4464 -1.9810  0.1356 -0.0717 -0.0621 -0.0092]\n","[-54.3955 -48.8944 -20.7340 -1.0797  0.0997  0.0772  0.0408  0.0378]\n","[-54.3836 -48.9051 -20.7340 -1.0797  0.0997  0.0772  0.0408  0.0377]\n","[-54.3834 -48.9052 -20.7340 -1.0797  0.0997  0.0772  0.0408  0.0377]\n","[-54.3834 -48.9052 -20.7340 -1.0797  0.0997  0.0772  0.0408  0.0377]\n","[-54.3834 -48.9052 -20.7340 -1.0797  0.0997  0.0772  0.0408  0.0377]\n","\n","Eigenvectors from orthogonal iterations: \n","[[-0.1853  0.2079  0.2574  0.3834  0.5393 -0.3564  0.4128 -0.0885]\n"," [-0.5309  0.4047  0.2861  0.1581  0.2906 -0.3637  0.4213 -0.3085]\n"," [-0.0312  0.1962  0.0413  0.3369  0.5134 -0.4545  0.4259 -0.1094]\n"," [-0.2760  0.5588  0.2974  0.3694  0.3603 -0.1413  0.2719 -0.4155]\n"," [-0.5249  0.4780  0.3161  0.3440  0.4335 -0.0795  0.3295 -0.5583]\n"," [-0.2318  0.1769  0.4512  0.4619  0.1416 -0.1137  0.3809 -0.2846]\n"," [-0.3945  0.2875  0.0537  0.1145  0.0623 -0.3439  0.2169 -0.0845]\n"," [-0.3490  0.3160  0.6748  0.4830  0.1397 -0.6137  0.3099 -0.5591]]\n","\n","Eigenvalues from NumPy: \n","[-54.3834 -48.9052 -20.7340 -1.0797  0.0997  0.0377  0.0408  0.0772]\n","\n","Eigenvectors from NumPy: \n","[[ 0.1853 -0.2079  0.2574 -0.3834 -0.5393  0.0885 -0.4128  0.3564]\n"," [ 0.5309 -0.4047  0.2861 -0.1581 -0.2906  0.3085 -0.4213  0.3637]\n"," [ 0.0312 -0.1962  0.0413 -0.3369 -0.5134  0.1094 -0.4259  0.4545]\n"," [ 0.2760 -0.5588  0.2974 -0.3694 -0.3603  0.4155 -0.2719  0.1413]\n"," [ 0.5249 -0.4780  0.3161 -0.3440 -0.4335  0.5583 -0.3295  0.0795]\n"," [ 0.2318 -0.1769  0.4512 -0.4619 -0.1416  0.2846 -0.3809  0.1137]\n"," [ 0.3945 -0.2875  0.0537 -0.1145 -0.0623  0.0845 -0.2169  0.3439]\n"," [ 0.3490 -0.3160  0.6748 -0.4830 -0.1397  0.5591 -0.3099  0.6137]]\n"]}]}]}