{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Schur decomposition"
      ],
      "metadata": {
        "id": "RzSDlfgPUCzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to `Schur theorem`, if $A\\in \\mathbf{R}^{n \\times n}$ is a square real matrix with real eigenvalues, then there exists an orthogonal matrix $Q$ and an upper triangular matrix $T$ such that\n",
        "\n",
        "$$A=QTQ^T$$\n",
        "\n",
        "We can show why this is true"
      ],
      "metadata": {
        "id": "Go0h4wvkyC7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Setup"
      ],
      "metadata": {
        "id": "oivz6pIXGM3X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For orthogonal matrix $Q_1^T=Q_1^{-1}$ and $Q_1^TQ_1=I$, by letting $Q_1=\\begin{bmatrix}q_1 & q_2 & \\cdots & q_n\\end{bmatrix}$, and $q_1$ being a normalized `eigenvector` of $A$, we can write\n",
        "\n",
        "$$\\begin{align*}\n",
        "Q_1^TAQ_1&=\\begin{bmatrix}q_1^T \\\\ q_{2:n}^T\\end{bmatrix}A\\begin{bmatrix}q_1 & q_{2:n}\\end{bmatrix} \\\\\n",
        "& =\\begin{bmatrix}q_1^TAq_1 & q_1^TAq_{2:n} \\\\ q_{2:n}^TAq_1 & q_{2:n}^TAq_{2:n}\\end{bmatrix}\n",
        "\\end{align*}$$"
      ],
      "metadata": {
        "id": "_lHxQHBczOh6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By `construction`, the upper-left block is the corresponding `eigenvalue` $\\lambda_1$, since\n",
        "\n",
        "$$q_1^TAq_1 = q_1^T(\\lambda_1q_1)=\\lambda_1q_1^Tq_1=\\lambda_1$$\n",
        "\n",
        "For the upper-right block, we denote it $B$\n",
        "\n",
        "$$B=q_1^TAq_{2:n}=\\begin{bmatrix}q_1^TAq_2 & q_1^TAq_3 & \\cdots & q_1^TAq_n \\end{bmatrix}$$\n",
        "\n",
        "The lower-left block is zero, since\n",
        "\n",
        "$$q_{2:n}^TAq_1=\\begin{bmatrix}q_2^T \\\\q_3^T \\\\ \\vdots \\\\q_n^T \\end{bmatrix}Aq_1=\\lambda_1\\begin{bmatrix}q_2^T \\\\q_3^T \\\\ \\vdots \\\\q_n^T \\end{bmatrix}q_1=\\begin{bmatrix}0 \\\\0 \\\\ \\vdots \\\\0 \\end{bmatrix}$$\n",
        "\n",
        "We denote the lower-right block $A_2$ and we have\n",
        "\n",
        "$$\\begin{align*}\n",
        "Q_1^TAQ_1&=\\begin{bmatrix}\\lambda_1 & B \\\\ 0 & A_2\\end{bmatrix}\n",
        "\\end{align*}$$\n",
        "\n",
        "or\n",
        "\n",
        "$$\\begin{align*}\n",
        "AQ_1&=Q_1\\begin{bmatrix}\\lambda_1 & B \\\\ 0 & A_2\\end{bmatrix}\n",
        "\\end{align*}$$"
      ],
      "metadata": {
        "id": "6UWPzdfPBqPA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition, $A_2$ contains the `remaining eigenvalues` $\\lambda_2 , \\cdots, \\lambda_n$ of $A$\n",
        "\n",
        "To see this, from the properties of similarity transformation, we know that $A$ and $Q_1^TAQ_1$ have the same eigenvalues\n",
        "\n",
        "Therefore\n",
        "\n",
        "$$\\begin{align*}\n",
        "\\det (A-\\lambda I)&=\\det (Q_1^TAQ_1-\\lambda I) \\\\\n",
        "&=\\det \\begin{bmatrix}\\lambda_1-\\lambda & B \\\\ 0 & A_2-\\lambda I\\end{bmatrix} \\\\\n",
        "& \\text{property of determinant}\\\\\n",
        "&= (\\lambda_1-\\lambda) \\det (A_2-\\lambda I)\n",
        "\\end{align*}$$"
      ],
      "metadata": {
        "id": "D96ESkIVGb0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Proof by induction"
      ],
      "metadata": {
        "id": "MHuuAkPCGUe-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For matrix of size one, Schur decomposition obviously exists\n",
        "\n",
        "So starting with matrix of size $n=2$, we know that there exists a Schur decomposition for matrix $A_2$ of size $n-1$:\n",
        "\n",
        "$$Q_2T_2Q_2^T=A_2$$\n",
        "\n",
        "or\n",
        "\n",
        "$$Q_2T_2=A_2Q_2$$\n",
        "\n",
        "We can proceed with `induction`"
      ],
      "metadata": {
        "id": "C8AoGPuZFhU1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we write\n",
        "\n",
        "$$Q=Q_1\\begin{bmatrix}1 & 0 \\\\ 0 & Q_2\\end{bmatrix}$$\n",
        "\n",
        "(since both $Q_1$ and $Q_2$ are orthogonal, $Q$ is orthogonal)\n",
        "\n",
        "we have for matrix $A$ of size $n$\n",
        "\n",
        "$$\\begin{align*}AQ &= A Q_1\\begin{bmatrix}1 & 0 \\\\ 0 & Q_2\\end{bmatrix} \\\\\n",
        "& = Q_1\\begin{bmatrix}\\lambda_1 & B \\\\ 0 & A_2\\end{bmatrix}\\begin{bmatrix}1 & 0 \\\\ 0 & Q_2\\end{bmatrix} \\\\\n",
        "&=Q_1 \\begin{bmatrix}\\lambda_1 & BQ_2 \\\\ 0 & A_2Q_2\\end{bmatrix} \\\\\n",
        "&=Q_1 \\begin{bmatrix}\\lambda_1 & BQ_2 \\\\ 0 & Q_2T_2\\end{bmatrix} \\\\\n",
        "&=Q_1 \\begin{bmatrix}1& 0 \\\\ 0 & Q_2\\end{bmatrix}\\begin{bmatrix}\\lambda_1 & BQ_2 \\\\ 0 & T_2\\end{bmatrix} \\\\\n",
        "& = Q\\begin{bmatrix}\\lambda_1 & BQ_2 \\\\ 0 & T_2\\end{bmatrix}\n",
        "\\end{align*}$$\n",
        "\n",
        "Now, we can show that Schur decomposition exists for matrix $A$ of size $n$ by letting\n",
        "\n",
        "$$T=\\begin{bmatrix}\\lambda_1 & BQ_2 \\\\ 0 & T_2\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "0Ch6hX8A_2pa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If $A$ is symmetric, then $T$ is upper triangular and symmetric at the same time, therefore, $T$ must be diagonal, meaning that symmetric matrices are diagonalizable, as we have known"
      ],
      "metadata": {
        "id": "TASdu2t5PHg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `Orthogonal` iterations"
      ],
      "metadata": {
        "id": "Q3r1s6EOgAva"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall our power iterations to find the dominant eigenvalue of $A$, by starting from an arbitrary vector $x$ and alternating between computing $y^k=Ax^k$ and normalizing and updating $x^k$ as $x^k=\\frac{y^k}{\\|y^k\\|}$"
      ],
      "metadata": {
        "id": "ZLXw7q3vjiz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get to Schur decomposition, we would like to do the iterations not just on a single vector $x$, but on $n$ orthonormal vectors that form an `orthogonal` matrix $Q_0$\n",
        "\n",
        "After each multiplication of $A$, we do `QR decomposition` such that we still have a set of orthonormal vectors for the next iteration\n",
        "\n",
        "$$AQ_i=Q_{i+1}R_{i+1}$$\n",
        "\n",
        "We can see that, if $Q_i \\rightarrow Q$ as $i\\rightarrow \\infty$, then $R_i$ must also converges to certain upper triangular $R$, and\n",
        "\n",
        "$$AQ=QR \\Rightarrow A=QRQ^T$$\n",
        "\n",
        "which is exactly the Schur decomposition we need where $T=R$"
      ],
      "metadata": {
        "id": "g7aCDu29gfgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can first evaluate orthogonal iterations on a square real matrix to get some feeling\n",
        "\n",
        "We start with $Q_0=I$\n",
        "\n",
        "We use `Householder` reflector for QR factorization"
      ],
      "metadata": {
        "id": "PaQNtZPckP0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.set_printoptions(formatter={'float': '{: 0.4f}'.format})\n",
        "\n",
        "plt.style.use('dark_background')\n",
        "# color: https://matplotlib.org/stable/gallery/color/named_colors.htm"
      ],
      "metadata": {
        "id": "E7IXLxroydqP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def householder(A):\n",
        "    m, n = A.shape\n",
        "    R = A.copy()\n",
        "    Q = np.identity(m)\n",
        "\n",
        "    for i in range(n):\n",
        "        x = R[i:, i]\n",
        "        v = np.sign(x[0]) * np.linalg.norm(x) * np.eye(x.shape[0])[:,0] + x\n",
        "        v /= np.linalg.norm(v)\n",
        "\n",
        "        # Since all entries in R[i:, :i] are zero from previous iteration\n",
        "        # applying transformation to R[i:, i:] would suffice\n",
        "        R[i:, i:] -= 2 * np.outer(v, v) @ R[i:, i:]\n",
        "\n",
        "        # If Q is needed explicitly\n",
        "        Q[i:, :] -= 2 * np.outer(v, v) @ Q[i:, :]\n",
        "\n",
        "    return Q.T, R\n",
        "\n",
        "def diagonalizable_mat(n):\n",
        "    # Create diagonal matrix to store eigenvalues\n",
        "    D = np.diag(np.concatenate((1000*np.random.rand(n//2)-400, 0.01*np.random.rand(n-n//2))))\n",
        "\n",
        "    # Get some orthogonal matrix Q using QR factorization based on Householder\n",
        "    Q, R = householder(np.random.rand(n, n))\n",
        "\n",
        "    # Use similarity transformation to create diagonalizable matrix with real eigenvalues\n",
        "    return Q @ D @ Q.T"
      ],
      "metadata": {
        "id": "BF5Ag0ajpknc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "A_size = 8\n",
        "A = diagonalizable_mat(A_size)\n",
        "\n",
        "A_original = A.copy()\n",
        "\n",
        "# Orthogonal iteration algorithm\n",
        "Q = np.eye(A.shape[0])\n",
        "Q_0 = Q.copy()\n",
        "\n",
        "num_iter = 41\n",
        "for i in range(num_iter):\n",
        "    Q, R = householder(A @ Q)\n",
        "    # Diagonal elements of R are approximation of eigenvalues\n",
        "    if i % 10 == 0:\n",
        "        print(R.diagonal())\n",
        "\n",
        "# Compare to NumPy\n",
        "eigenvalues, eigenvectors = np.linalg.eig(A_original)\n",
        "print(f'\\nEigenvalues from NumPy: \\n{eigenvalues}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWHibPJJkySL",
        "outputId": "71b0261a-1e8d-4096-98de-f36c7842bb05"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-141.4565 -103.2169 -30.1985 -151.7128 -0.0034  0.0330 -0.0009 -0.0017]\n",
            "[ 549.9817  332.4361  198.6585 -25.4599  0.0087  0.0016  0.0016  0.0006]\n",
            "[ 550.7143  331.9940  198.6585 -25.4599  0.0087  0.0016  0.0016  0.0006]\n",
            "[ 550.7143  331.9939  198.6585 -25.4599  0.0087  0.0016  0.0016  0.0006]\n",
            "[ 550.7143  331.9939  198.6585 -25.4599  0.0087  0.0016  0.0016  0.0006]\n",
            "\n",
            "Eigenvalues from NumPy: \n",
            "[ 550.7143  331.9939  198.6585 -25.4599  0.0087  0.0006  0.0016  0.0016]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the orthogonal iterations converge very quickly\n",
        "\n",
        "The fact that the algorithm computes all eigenvalues simultaneously makes it far more efficient than standard power iterations that compute eigenvalues one by one"
      ],
      "metadata": {
        "id": "94GqvdFsekuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o4K140OV81cr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}