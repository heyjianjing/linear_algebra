{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Gain of a matrix"
      ],
      "metadata": {
        "id": "CfWMiHIGCqu8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let $A\\in \\mathbf{R}^{m \\times n}$ (tall, square or fat), for $x\\in \\mathbf{R}^n$\n",
        "\n",
        "$$\\frac{\\|Ax\\|}{\\|x\\|}$$\n",
        "\n",
        "gives the amplification factor or `gain` of $A$ in the `direction` of $x$"
      ],
      "metadata": {
        "id": "zIzK1MImE5hV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Largest gain and matrix norm"
      ],
      "metadata": {
        "id": "Xxg3ty2wN2PF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The largest gain\n",
        "\n",
        "$$\\max\\frac{\\|Ax\\|}{\\|x\\|}, x\\neq0$$\n",
        "\n",
        "is known as `matrix norm` or `spectral norm` of $A$, written as $\\|A\\|$\n",
        "\n",
        "Recall the upper and lower bound of quadratic form in terms of the eigenvalues of a symmetric matrix $S$\n",
        "\n",
        "$$\\lambda_{\\min} \\|x\\|^2 \\leq x^TSx \\leq \\lambda_{\\max} \\|x\\|^2 $$\n",
        "\n",
        "we have\n",
        "\n",
        "$$\\max\\frac{\\|Ax\\|^2}{\\|x\\|^2}=\\max\\frac{x^T(A^TA)x}{\\|x\\|^2}=\\boxed{\\lambda_{\\max} \\,(A^TA)}$$\n",
        "\n",
        "Therefore, the matrix norm is\n",
        "\n",
        "$$\\|A\\|=\\sqrt{\\lambda_{\\max} \\,(A^TA)}$$"
      ],
      "metadata": {
        "id": "Eaq5A36IN5Eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Smallest gain"
      ],
      "metadata": {
        "id": "NZN8qK58OuMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly\n",
        "\n",
        "$$\\min\\frac{\\|Ax\\|}{\\|x\\|}, x\\neq0=\\sqrt{\\lambda_{\\min} \\,(A^TA)}$$"
      ],
      "metadata": {
        "id": "Z-m231bMOwLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So\n",
        "\n",
        "* `max gain` input direction is $x=q_1$, eigenvector of $A^TA$ associated with $\\lambda_{\\max}$\n",
        "* `min gain` input direction is $x=q_n$, eigenvector of $A^TA$ associated with $\\lambda_{\\min}$"
      ],
      "metadata": {
        "id": "ZKmhrzM0Pgwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Nullspace`, for example, represents the `directions` where gain is `zero`\n",
        "\n",
        "In case $Ax$ is tiny, which for practical purposes can be considered as $x\\in N(A)$, matrix norm gives a quantitative way of talking about `nullspace`"
      ],
      "metadata": {
        "id": "a4glyprkeHqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(formatter={'float': '{: 0.4f}'.format})"
      ],
      "metadata": {
        "id": "30G10sbbQVwG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tall_matrix=True\n",
        "\n",
        "if tall_matrix:\n",
        "    A = np.array([[1, 2],\n",
        "                  [3, 4],\n",
        "                  [5, 6]])\n",
        "else:\n",
        "    A = np.array([[1, 3, 5],\n",
        "                  [2, 4, 6]])\n",
        "\n",
        "A_TA = np.dot(A.T, A)\n",
        "\n",
        "eigenvalues, eigenvectors = np.linalg.eig(A_TA)\n",
        "\n",
        "print(f'Eigenvalues \\n{eigenvalues}')\n",
        "print(f'Sqrt eigenvalues \\n{np.sqrt(eigenvalues)}')\n",
        "print(f'\\nEigenvectors \\n{eigenvectors}')\n",
        "\n",
        "# Double check index\n",
        "print(f'\\nLargest gain \\n{np.linalg.norm(A @ eigenvectors[:, 1])}')\n",
        "print(f'\\nSmallest gain \\n{np.linalg.norm(A @ eigenvectors[:, 0])}')"
      ],
      "metadata": {
        "id": "KtV1_unKE5ML",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880b4213-1241-4784-a0ca-4d804d059639"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eigenvalues \n",
            "[ 0.2645  90.7355]\n",
            "Sqrt eigenvalues \n",
            "[ 0.5143  9.5255]\n",
            "\n",
            "Eigenvectors \n",
            "[[-0.7849 -0.6196]\n",
            " [ 0.6196 -0.7849]]\n",
            "\n",
            "Largest gain \n",
            "9.52551809156511\n",
            "\n",
            "Smallest gain \n",
            "0.5143005806586443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case of `fat matrix` here, smallest gain is zero as $A^TA$ is low rank and is guaranteed to have non-trivial `nullspace`"
      ],
      "metadata": {
        "id": "8W-sy7Lsejd7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pjvaZ_yDQlKw"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}