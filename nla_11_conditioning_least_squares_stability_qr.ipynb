{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPr2TS2Cczpf/b5fOBzU7U0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#### Least squares"],"metadata":{"id":"s9JRN0lOHziu"}},{"cell_type":"markdown","source":["For $b=Ax$, $A\\in \\mathbf{R}^{m \\times n}$, $m>n$, **`full rank`**\n","\n","The least squares problem finds $x_{ls}$ that `minimizes` $$\\|Ax-b\\|^2$$\n","\n","and we know the analytical equation\n","\n","$$x_{ls}=(A^TA)^{-1}A^Tb$$"],"metadata":{"id":"LPIeN-tCB2ps"}},{"cell_type":"markdown","source":["We would like to see how different QR factorization-based algorithms perform in solving an ill-conditioned least squares problem"],"metadata":{"id":"BBRPygA4__Ee"}},{"cell_type":"markdown","source":["#### Conditioning parameters"],"metadata":{"id":"n4pll0zaFehH"}},{"cell_type":"markdown","source":["Conditioning refers to sensitivity of `solutions` $x$ and $y=Ax$ to perturbations in `data` $A$ and $b$\n","\n","Three dimensionless parameters are used"],"metadata":{"id":"wAgvWb6Xfg1P"}},{"cell_type":"markdown","source":["`Condition number`\n","\n","$$\\kappa(A)=\\frac{\\sigma_{\\max}}{\\sigma_{\\min}}=\\|A\\|\\|A^+\\|$$\n","\n","where $A^+$ is the pseudoinverse, $\\sigma_{\\max}$ and $\\sigma_{\\min}$ are largest and smallest singular values, respectively\n","\n","This is a generalized version of condition number for square matrices (which would be $\\kappa(A)=\\|A\\|\\|A^{-1}\\|$)\n","\n","$1\\leq \\kappa(A) \\leq \\infty$"],"metadata":{"id":"lWi-1-QKgd1S"}},{"cell_type":"markdown","source":["`Closeness of fit`\n","\n","$$\\theta=\\cos^{-1}\\frac{\\|y\\|}{\\|b\\|}$$\n","\n","$0 \\leq \\theta \\leq \\frac{\\pi}{2}$"],"metadata":{"id":"YpwWeq-Sg16N"}},{"cell_type":"markdown","source":["How much $\\|y\\|$ falls short of its `maximum possible value`, given $\\|A\\|, \\|x\\|$\n","\n","$$\\eta=\\frac{\\|A\\|\\|x\\|}{\\|y\\|}=\\frac{\\|A\\|\\|x\\|}{\\|Ax\\|}\\leq\\frac{\\sigma_{\\max}\\|x\\|}{\\sigma_{\\min}\\|x\\|}=\\kappa(A)$$\n","\n","This comes from that smallest gain of $A$ corresponds to the smallest singular value\n","\n","$$\\min_{x\\neq 0} \\frac{\\|Ax\\|}{\\|x\\|} = \\sigma_{\\min}(A) \\rightarrow \\|Ax\\|\\geq \\sigma_{\\min} \\|x\\|$$\n","\n","So, we have\n","\n","$1\\leq \\eta \\leq \\kappa(A)$"],"metadata":{"id":"x7LYN_2whCNs"}},{"cell_type":"markdown","source":["With these parameters, we can compute (relative) `condition numbers` describing sensitivities of $y$ and $x$ to perturbations in $b$ and $A$\n","\n","$$\\begin{bmatrix}\n"," & y & x \\\\ b & \\frac{1}{\\cos \\theta} & \\frac{\\kappa(A)}{\\eta\\cos \\theta} \\\\\n"," A & \\frac{\\kappa(A)}{\\cos \\theta} & \\kappa(A) + \\frac{\\kappa(A)^2\\tan \\theta}{\\eta}\n","\\end{bmatrix}$$"],"metadata":{"id":"joizRfLTqkj3"}},{"cell_type":"markdown","source":["#### A bit more details"],"metadata":{"id":"YkwRxb03xfIK"}},{"cell_type":"markdown","source":["Recall relative condition number is defined as\n","\n","$$\\kappa = \\sup_{\\delta x}\\left(\\frac{\\|\\delta f\\|}{\\|f(x)\\|}\\left.\\right/\\frac{\\|\\delta x\\|}{\\|x\\|}\\right)$$\n","\n","In case $f$ is differentiable, we have\n","\n","$$\\kappa = \\frac{\\|J(x)\\|}{\\|f(x)\\|/\\|x\\|}$$"],"metadata":{"id":"VeQG0xR4xisC"}},{"cell_type":"markdown","source":["##### Sensitivity $b\\rightarrow y$"],"metadata":{"id":"w4O4vZm2yCFU"}},{"cell_type":"markdown","source":["Since $y=Ax, x=A^+b$, we have $y=AA^+b=A(A^TA)^{-1}A^Tb$\n","\n","Notice that $A(A^TA)^{-1}A^T$ is a projection matrix and we know, for a nonzero vector $v\\in \\mathbf{R}^m$, there are only three possibilities\n","\n","* if $v\\in R(A)$, $A(A^TA)^{-1}A^Tv=v$ and therefore, eigenvalue is 1\n","* if $v\\in R(A)^{\\perp}$, $A(A^TA)^{-1}A^Tv=0$ and therefore, eigenvalue is 0\n","* if $v$ has components in both $R(A)$ and $R(A)^{\\perp}$\n","    * we write $v=v_{R(A)}+v_{R(A)^{\\perp}}$, then $A(A^TA)^{-1}A^Tv=v_{R(A)}$\n","    * this does not introduce any new eigenvalue since $v$ is not an eigenvector here\n","\n","Therefore, there are no eigenvalues other than 1 and 0 for $A(A^TA)^{-1}A^T$\n","\n","As a result, the matrix norm of projection matrix is\n","\n","$$\\|A(A^TA)^{-1}A^T\\|=1$$\n","\n","Now, we can write sensitivity of $y$ to perturbations in $b$ as\n","\n","$$\\kappa_{b\\rightarrow y}=\\frac{\\|A(A^TA)^{-1}A^T\\|}{\\|y\\|/\\|b\\|}=\\frac{1}{\\cos \\theta}$$"],"metadata":{"id":"dlfFfVBHyN2c"}},{"cell_type":"markdown","source":["##### Sensitivity $b\\rightarrow x$"],"metadata":{"id":"esTCXCu12jL3"}},{"cell_type":"markdown","source":["$$\\kappa_{b\\rightarrow x}=\\frac{\\|A^+\\|}{\\|x\\|/\\|b\\|}=\\|A^+\\|\\frac{\\|b\\|}{\\|y\\|}\\frac{\\|y\\|}{\\|x\\|}=\\|A^+\\|\\frac{1}{\\cos \\theta}\\frac{\\|A\\|}{\\eta}=\\frac{\\kappa(A)}{\\eta \\cos \\theta}$$"],"metadata":{"id":"hTURZDLw2l48"}},{"cell_type":"markdown","source":["Derivation of other two sensitivity metrics: sensitivity $A\\rightarrow y$ and $A\\rightarrow x$, see NLA book"],"metadata":{"id":"UOgUOz8Si2aP"}},{"cell_type":"markdown","source":["#### Problem setup"],"metadata":{"id":"OamUjAHmrhte"}},{"cell_type":"markdown","source":["This is a problem from NLA book, where $A$ is ill-conditioned\n","\n","The setup is to compare final entry of $x$, for which the true value is `1`"],"metadata":{"id":"SsabkC2B5RcG"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","np.set_printoptions(formatter={'float': '{: 0.4f}'.format})\n","np_seed = 41\n","\n","plt.style.use('dark_background')\n","# color: https://matplotlib.org/stable/gallery/color/named_colors.htm"],"metadata":{"id":"64VKzPhM8fWC","executionInfo":{"status":"ok","timestamp":1733281566778,"user_tz":300,"elapsed":113,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}}},"execution_count":64,"outputs":[]},{"cell_type":"code","source":["m = 100\n","n = 15\n","\n","t = np.linspace(0, 1, m)\n","\n","# Vandermonde\n","A_1 = np.vander(t, n, increasing=True)\n","cond_num = np.linalg.cond(A_1)\n","print(f\"Condition number: {cond_num:.4e}\")\n","b_1 = np.exp(np.sin(4 * t)) / 2006.787453080206\n","\n","print(A_1.shape)\n","print(b_1.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GYf7zVmpuaBY","executionInfo":{"status":"ok","timestamp":1733281566908,"user_tz":300,"elapsed":4,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}},"outputId":"41b7abc7-b5ad-446a-9ea6-f8edfa9458f6"},"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Condition number: 2.2718e+10\n","(100, 15)\n","(100,)\n"]}]},{"cell_type":"markdown","source":["We first use NumPy solver to get sufficiently accurate result\n","\n","The NumPy solver is based on QR, therefore, its result serves as a reference to compare different QR algorithms"],"metadata":{"id":"w-hQfUabnawA"}},{"cell_type":"code","source":["# Use NumPy solver to obtain to sufficient accuracy the conditioning parameters\n","x, _, _, _ = np.linalg.lstsq(A_1, b_1, rcond=None)\n","y = A_1 @ x\n","\n","# Condition number\n","kappa = np.linalg.cond(A_1)\n","print(f\"kappa = {kappa:.4e}\")\n","\n","# Closedness of fit (theta)\n","theta = np.arcsin(np.linalg.norm(b_1 - y) / np.linalg.norm(b_1))\n","print(f\"theta = {theta:.4e}\")\n","\n","# Deviation (eta)\n","eta = (np.linalg.norm(A_1) * np.linalg.norm(x)) / np.linalg.norm(y)\n","print(f\"eta = {eta:.4e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zQglZSGjx6ZA","executionInfo":{"status":"ok","timestamp":1733281566908,"user_tz":300,"elapsed":3,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}},"outputId":"372e4673-9a71-49d5-d176-c00cf65703b9"},"execution_count":66,"outputs":[{"output_type":"stream","name":"stdout","text":["kappa = 2.2718e+10\n","theta = 3.7461e-06\n","eta = 2.3732e+05\n"]}]},{"cell_type":"code","source":["b_y = 1 / np.cos(theta)\n","b_x = kappa / (eta * np.cos(theta))\n","\n","A_y = kappa / np.cos(theta)\n","A_x = kappa + (kappa**2 * np.tan(theta)) / eta\n","\n","print(f\"b_y = {b_y:.4e}\")\n","print(f\"b_x = {b_x:.4e}\")\n","print(f\"A_y = {A_y:.4e}\")\n","print(f\"A_x = {A_x:.4e}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHHTkSB813y5","executionInfo":{"status":"ok","timestamp":1733281566908,"user_tz":300,"elapsed":2,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}},"outputId":"daf041c5-503b-4072-caf0-b92b7a63b6f2"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["b_y = 1.0000e+00\n","b_x = 9.5727e+04\n","A_y = 2.2718e+10\n","A_x = 3.0864e+10\n"]}]},{"cell_type":"markdown","source":["#### QR factorization and back substitution"],"metadata":{"id":"5cswJD8X6LGp"}},{"cell_type":"markdown","source":["We now explore `reduced` QR factorization (since $m>n$) and back substitution to solve least squares\n","\n","* $A=QR$ with `Householder`, `Givens`, or `MGS`\n","* Update $b\\leftarrow Q^Tb$\n","* Solve upper triangular system $Rx=b$ for $x$ with `back substitution`"],"metadata":{"id":"oJN8PglU77aa"}},{"cell_type":"markdown","source":["##### Householder"],"metadata":{"id":"1pEf5gAi_vxk"}},{"cell_type":"code","source":["def householder(A):\n","    m, n = A.shape\n","    R = A.copy()\n","    Q = np.identity(m)\n","\n","    # For fat matrices, we only process up to the mth column\n","    for i in range(min(m, n)):\n","        x = R[i:, i]\n","        if np.allclose(x, 0):\n","            continue  # Skip if x is a zero vector\n","\n","        v = x.copy()\n","        sng = np.sign(x[0]) if x[0] != 0 else 1.0 # Per convention in NLA\n","        v[0] += sng * np.linalg.norm(x)\n","        v /= np.linalg.norm(v)\n","\n","        # Since all entries in R[i:, :i] are zero from previous iteration\n","        # applying transformation to R[i:, i:] would suffice\n","        R[i:, i:] -= 2 * np.outer(v, v) @ R[i:, i:]\n","\n","        # If Q is needed explicitly\n","        Q[i:, :] -= 2 * np.outer(v, v) @ Q[i:, :]\n","\n","    return Q.T, R\n","\n","def back_substitution(R, b):\n","    m, n = R.shape\n","    x = np.zeros(n)\n","    for i in range(n - 1, -1, -1):\n","        x[i] = (b[i] - np.dot(R[i, i + 1:], x[i + 1:])) / R[i, i]\n","    return x"],"metadata":{"id":"qI66Gk5i6GCD","executionInfo":{"status":"ok","timestamp":1733281567017,"user_tz":300,"elapsed":110,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}}},"execution_count":68,"outputs":[]},{"cell_type":"code","source":["Q, R = householder(A_1)\n","print(Q.shape)\n","print(R.shape)\n","b_hh = Q[:, :A_1.shape[1]].T @ b_1\n","x_hh = back_substitution(R[:A_1.shape[1],:], b_hh)\n","print(f\"x[15] = {x_hh[14]:.10f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae-mnp_99krC","executionInfo":{"status":"ok","timestamp":1733281567017,"user_tz":300,"elapsed":1,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}},"outputId":"20d79bd0-09e5-4b4a-fd5b-a59899d27913"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["(100, 100)\n","(100, 15)\n","x[15] = 0.9999999830\n"]}]},{"cell_type":"markdown","source":["##### Givens rotations"],"metadata":{"id":"ijV9hhxv_FT9"}},{"cell_type":"code","source":["def givens_rotation(A):\n","    m, n = A.shape\n","    Q = np.identity(m)\n","    for col in range(min(m, n)):\n","        for row in range(col+1, m):\n","            if A[row, col] != 0:\n","                alpha = np.sqrt(A[col, col]**2 + A[row, col]**2)\n","                c = A[col, col] / alpha\n","                s = A[row, col] / alpha\n","\n","                G = np.identity(m)\n","                G[row, col] = -s\n","                G[col, row] = s\n","                G[col, col] = c\n","                G[row, row] = c\n","\n","                A = G @ A\n","                Q = Q @ G.T\n","\n","    return Q, A"],"metadata":{"id":"oVWj01Wg-gby","executionInfo":{"status":"ok","timestamp":1733281567017,"user_tz":300,"elapsed":1,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}}},"execution_count":70,"outputs":[]},{"cell_type":"code","source":["Q, R = givens_rotation(A_1)\n","print(Q.shape)\n","print(R.shape)\n","b_givens = Q[:, :A_1.shape[1]].T @ b_1\n","x_givens = back_substitution(R[:A_1.shape[1],:], b_givens)\n","print(f\"x[15] = {x_givens[14]:.10f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPmsIwCq_QdT","executionInfo":{"status":"ok","timestamp":1733281567757,"user_tz":300,"elapsed":741,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}},"outputId":"2e9a65a3-45ce-42ec-ca00-731de54332c1"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["(100, 100)\n","(100, 15)\n","x[15] = 1.0000000564\n"]}]},{"cell_type":"markdown","source":["##### Modified Gram-Schmidt"],"metadata":{"id":"V00YYQqj_Zuy"}},{"cell_type":"code","source":["def general_gram_schmidt(A, modified=True):\n","    _, k = A.shape  # Get number of vectors (columns) in A\n","    Q = []  # Start with empty list, as we don't know how many q's are there\n","    R = np.zeros((0, k))  # Same here\n","\n","    for i in range(k):\n","        # Loop over all a_i\n","        q = A[:, i].copy()\n","\n","        # This skips when i=0\n","        for j in range(len(Q)):\n","            if modified:\n","                R[j, i] = np.dot(Q[j], q)\n","            else:\n","                R[j, i] = np.dot(Q[j], A[:, i])\n","            q -= R[j, i] * Q[j]\n","\n","        # Compute norm of new q\n","        norm_q = np.sqrt(np.dot(q, q))\n","\n","        # Only add q to Q if it is not small\n","        if norm_q > 1e-10:  # Tolerance\n","            q /= norm_q\n","            Q.append(q)\n","\n","            # Expand R to include new row corresponding to new q\n","            new_row = np.zeros((1, k))\n","            new_row[0, i] = norm_q\n","            R = np.vstack([R, new_row])\n","\n","    Q = np.column_stack(Q)  # Convert to array\n","\n","    return Q, R"],"metadata":{"id":"1g5dlKjH_cGc","executionInfo":{"status":"ok","timestamp":1733281567757,"user_tz":300,"elapsed":3,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}}},"execution_count":72,"outputs":[]},{"cell_type":"code","source":["Q, R = general_gram_schmidt(A_1) # Reduced QR by construction\n","print(Q.shape)\n","print(R.shape)\n","b_mgs = Q.T @ b_1\n","x_mgs = back_substitution(R, b_mgs)\n","print(f\"x[15] = {x_mgs[14]:.10f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"imKWSJwV_e33","executionInfo":{"status":"ok","timestamp":1733281567757,"user_tz":300,"elapsed":2,"user":{"displayName":"Jianjing Zhang","userId":"07583447684872889447"}},"outputId":"2dc31400-25f4-4b0c-f727-34bc51ad9a70"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["(100, 15)\n","(15, 15)\n","x[15] = 0.9796910998\n"]}]},{"cell_type":"markdown","source":["We see that both Householder and Givens work well, while MGS's result looks poor. However, it can be stabilized by using an augmented system of equations, see NLA Theorem 19.2"],"metadata":{"id":"lJEveKV7AAT0"}},{"cell_type":"markdown","source":["#### Note"],"metadata":{"id":"wz5ThoCHpVKS"}},{"cell_type":"markdown","source":["Since the matrix is very ill-conditioned, it is essentially underdetermined and an infinite number of $x$ can reconstruct $b$ with similar accuracy\n","\n","Therefore, we should not compare solution $x$ between QR-based solver with other solvers, since there is no guarantee they lead to same \"types\" of solutions\n","\n","This example does not show that QR finds the \"true\" solution $x$, since there is no true solution for underdetermined system. The purpose is to show numerical stability among different QR algorithms"],"metadata":{"id":"w81790irokz6"}},{"cell_type":"code","source":[],"metadata":{"id":"PSAW_vElokAn"},"execution_count":null,"outputs":[]}]}